P4
Data wrangling using Pig

Create a CSV file dataset using Text Editor and save its as emp_data.csv 

id,name,age,city,salary 
1,John Doe,28,New York,-50000 
2,Jane Smith,34,Los Angeles,60000 
3,Mike Johnson,25,Chicago,45000.45 
4,Linda Green,40,New York,75000.55 
5,James White,29,Los Angeles,55000 
6,Patricia Brown,50,Chicago,-80000 
7,Robert Black,,New York,48000 
8,Emily Davis,27,Chicago,49000 
9,William Harris,35,Los Angeles,62000 
10,Elizabeth Clark,30,New York,52000 

Create a CSV file dataset using Text Editor and save its as dept_data.csv 

id,dept 
1,Sales 
2,Marketing 
3,IT 
4,HR 
5,Finance 
6,Operations 
7,Sales 
8,IT 
9,Marketing 
10,HR

1.Upload the CSV files to hadoop file system.
2.Start Apache Pig by entering pig command.
3.Use the LOAD function to load data from HDFS or a local file. 
4.Inspect the Data 
5.Data Cleaning 
Remove Null or Invalid Entries: 
clean_data = FILTER raw_data BY (age IS NOT NULL AND salary > 0); 
6.Data Transformation 
grouped_data = GROUP formatted_data BY city; 
Aggregate Data: 
city_salary = FOREACH grouped_data GENERATE group AS city, AVG(formatted_data.salary_rounded) AS avg_salary;

7.	Store Results 

Save the processed data back to HDFS or export it to a file. 
STORE city_salary INTO 'emp_data' USING PigStorage(','); 

8.	Join Datasets: 

other_data = LOAD â€˜dept_data.csv' USING PigStorage(',') AS (id:int, dept:chararray); 
joined_data = JOIN formatted_data BY id, other_data BY id; 
 
 
9.	Data Filtering and Sorting 

Filter Specific Records: 
high_earners = FILTER formatted_data BY salary_rounded > 50000; 
 
Sort Data: 
sorted_data = ORDER high_earners BY salary_rounded DESC; 
 

10.	Store Results 

Save the processed data back to HDFS or export it to a file. 
STORE sorted_data INTO 'joint_data' USING PigStorage(',');


